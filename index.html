<!DOCTYPE html>
<html>
<head>
  <title>PlanGPT</title>
  <meta charset="utf-8">
  <!-- <meta name="description"
        content="æå‡ç©ºé—´è®¤çŸ¥ä¸å†³ç­–èƒ½åŠ›çš„è§„åˆ’å¤§æ¨¡å‹ï¼ˆPlanGPTç³»åˆ—ï¼‰"> -->
  <meta name="description"
        content="Planning Large Language Models for Enhancing Spatial Cognition and Decision-Making Abilities">
  <meta name="keywords" content="PlanGPT, PlanBench-Text, PlanBench-VL, PlanGPT-VL, BSAI, artificial general intelligence">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- <title>æå‡ç©ºé—´è®¤çŸ¥ä¸å†³ç­–èƒ½åŠ›çš„è§„åˆ’å¤§æ¨¡å‹ï¼ˆPlanGPTç³»åˆ—ï¼‰</title> -->
  <title>Planning Large Language Models for Enhancing Spatial Cognition and Decision-Making Abilities</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./css/bulma.min.css">
  <link rel="stylesheet" href="./css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./css/bulma-slider.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./css/index.css">
  <link rel="stylesheet" href="./css/leaderboard.css">

  <style>
    .hidden {
      display: none;
    }
    
    .sticky-menu {
      position: -webkit-sticky; /* æ”¯æŒ Safari */
      position: sticky;
      top: 4rem;
    }

  .news-item {
    display: flex;
    align-items: baseline;
    margin-bottom: 8px;
    gap: 7px;
  }

  .date {
    flex-shrink: 0;
    display: inline-block;
    width: 120px; /* å›ºå®šå®½åº¦ç¡®ä¿æ—¥æœŸéƒ¨åˆ†å¯¹é½ */
    margin-right: 10px; /* æ—¥æœŸå’Œæ–‡æœ¬ä¹‹é—´çš„é—´è· */
  }

  .news-text {
    display: inline;
    flex-grow: 1;
  }

  p {
    margin: 0;
  }
  </style>
</head>

<body>
  <section class="section">
    <div class="container">
      <div class="columns">
        
        <!-- å·¦ä¾§ç›®å½•æ  -->
        <div class="column is-2">
          <!-- <aside class="menu sticky-menu is-hidden-mobile">
            <p class="menu-label">ç›®å½•</p>
            <ul class="menu-list">
              <li><a href="#PlanGPT-1/1.5">PlanGPT-1/1.5</a></li>
              <li><a href="#PlanBenchè§„åˆ’çŸ¥è¯†åŸºå‡†">PlanBenchè§„åˆ’çŸ¥è¯†åŸºå‡†</a></li>
              <li><a href="#PlanBenchè§„åˆ’å›¾è¯†åŸºå‡†">PlanBenchè§„åˆ’å›¾è¯†åŸºå‡†</a></li>
              <li><a href="#PlanGPT-VL">PlanGPT-VL</a></li>
              <li><a href="#æ•°æ®åˆæˆæŠ€æœ¯ç ”ç©¶">æ•°æ®åˆæˆæŠ€æœ¯ç ”ç©¶</a></li>
              <li><a href="#ç±»è„‘ç©ºé—´æ™ºèƒ½ï¼šä½ç½®ç¼–ç èµ‹èƒ½å¤§æ¨¡å‹">ç±»è„‘ç©ºé—´æ™ºèƒ½ï¼šä½ç½®ç¼–ç èµ‹èƒ½å¤§æ¨¡å‹</a></li>
              <li><a href="#ç”Ÿæ´»åœˆå¤§æ¨¡å‹">ç”Ÿæ´»åœˆå¤§æ¨¡å‹</a></li>
            </ul>
          </aside> -->
          <aside class="menu sticky-menu is-hidden-mobile">
            <p class="menu-label">Table of Contents</p>
            <ul class="menu-list">
              <li><a href="#PlanGPT-1/1.5">PlanGPT-1/1.5</a></li>
              <li><a href="#PlanBenchè§„åˆ’çŸ¥è¯†åŸºå‡†">PlanBench Planning Knowledge Benchmark</a></li>
              <li><a href="#PlanBenchè§„åˆ’å›¾è¯†åŸºå‡†">PlanBench Planning Visual Recognition Benchmark</a></li>
              <li><a href="#PlanGPT-VL">PlanGPT-VL</a></li>
              <li><a href="#æ•°æ®åˆæˆæŠ€æœ¯ç ”ç©¶">Data Synthesis Technology Research</a></li>
              <li><a href="#ç±»è„‘ç©ºé—´æ™ºèƒ½ï¼šä½ç½®ç¼–ç èµ‹èƒ½å¤§æ¨¡å‹">Brain-inspired Spatial Intelligence: Positional Encoding Empowering Large Models</a></li>
              <li><a href="#ç”Ÿæ´»åœˆå¤§æ¨¡å‹">Life Circle Large Model</a></li>
            </ul>
          </aside>
          <!-- <div class="dropdown is-hidden-desktop">
            <div class="dropdown-trigger">
              <button class="button is-primary" aria-haspopup="true" aria-controls="dropdown-menu">
                <span>ç›®å½•</span>
                <span class="icon is-small">
                  <i class="fas fa-angle-down" aria-hidden="true"></i>
                </span>
              </button>
            </div>
            <div class="dropdown-menu" id="dropdown-menu" role="menu">
              <div class="dropdown-content">
                <a href="#PlanGPT-1/1.5" class="dropdown-item">PlanGPT-1/1.5</a>
                <a href="#PlanBenchè§„åˆ’çŸ¥è¯†åŸºå‡†" class="dropdown-item">PlanBenchè§„åˆ’çŸ¥è¯†åŸºå‡†</a>
                <a href="#PlanBenchè§„åˆ’å›¾è¯†åŸºå‡†" class="dropdown-item">PlanBenchè§„åˆ’å›¾è¯†åŸºå‡†</a>
                <a href="#PlanGPT-VL" class="dropdown-item">PlanGPT-VL</a>
                <a href="#æ•°æ®åˆæˆæŠ€æœ¯ç ”ç©¶" class="dropdown-item">æ•°æ®åˆæˆæŠ€æœ¯ç ”ç©¶</a>
                <a href="#ç±»è„‘ç©ºé—´æ™ºèƒ½ï¼šä½ç½®ç¼–ç èµ‹èƒ½å¤§æ¨¡å‹" class="dropdown-item">ç±»è„‘ç©ºé—´æ™ºèƒ½ï¼šä½ç½®ç¼–ç èµ‹èƒ½å¤§æ¨¡å‹</a>
                <a href="#ç”Ÿæ´»åœˆå¤§æ¨¡å‹" class="dropdown-item">ç”Ÿæ´»åœˆå¤§æ¨¡å‹</a>
              </div>
            </div>
          </div> -->
        </div>

        <!-- å³ä¾§å†…å®¹ -->
        <div class="column is-10">

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="maintitle is-1 publication-title is-bold">
            <!-- <span class="PlanGPT" style="vertical-align: middle">æå‡ç©ºé—´è®¤çŸ¥ä¸å†³ç­–èƒ½åŠ›çš„è§„åˆ’å¤§æ¨¡å‹<br>ï¼ˆPlanGPTç³»åˆ—ï¼‰</span> -->
            <span class="PlanGPT" style="vertical-align: middle">Planning Large Language Models for Enhancing Spatial Cognition and Decision-Making Abilities</span>
          </h1>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="section">
  <div class="container" style="margin-bottom: 2vh;">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="subtitle is-3">ğŸ””News</h2>
        <div class="content has-text-justified">
          <div class="news-item">
            <span class="date is-size-6 has-text-grey is-italic">[2025-05-20]</span>
            <span class="news-text">PlanGPT-VLå·²æ­£å¼åœ¨Modelscopeå¹³å°å¼€æºï¼Œå¹¶åŒæ­¥å¼€æ”¾æµ‹è¯•é€šé“ï¼Œæ¬¢è¿è¯•ç”¨ä¸åé¦ˆ.</span>
          </div>
          <div class="news-item">
            <span class="date is-size-6 has-text-grey is-italic">[2025-05-20]</span>
            <span class="news-text">åŒæµå¤§å­¦æ ¡åº†æ—¥ï¼šå·¥ç¨‹æ™ºèƒ½ç ”ç©¶é™¢ã€åŸå¸‚æ—¶ç©ºæ™ºèƒ½ç ”ç©¶ä¸­å¿ƒæˆç«‹.</span>
          </div>
          <div class="news-item">
            <span class="date is-size-6 has-text-grey is-italic">[2025-05-20]</span>
            <span class="news-text">â€œå†²ä¹‹åœºâ€â€”â€”AIèµ‹èƒ½æ—¶ç©ºæ™ºèƒ½è®ºå›ã€PlanGPT-2ç³»åˆ—æˆæœå®£è®²ä¸é™†ç»­å‘å¸ƒ.</span>
          </div>
          <div class="news-item">
            <span class="date is-size-6 has-text-grey is-italic">[2025-05-16]</span>
            <span class="news-text">ç¥è´ºå®éªŒå®¤æœ±èµ«åŒå­¦2ç¯‡å…³äºæ•°æ®åˆæˆæŠ€æœ¯çš„é•¿è®ºæ–‡ã€ŠFANNOã€‹å’Œã€ŠTag-Instructã€‹è¢«è®¡ç®—æœºé¡¶ä¼šACL findingsæ¥æ”¶.</span>
          </div>
          <div class="news-item">
            <span class="date is-size-6 has-text-grey is-italic">[2025-05-09]</span>
            <span class="news-text">ç¥è´ºå®éªŒå®¤é˜¶æ®µæ€§æˆæœPlanGPT-1.5è¢«é¡¶ä¼šACL Industry Trackæ¥æ”¶ï¼Œå¹¶è·å¾—Oral Presentationæœºä¼š.</span>
          </div>
          <div class="news-item">
            <span class="date is-size-6 has-text-grey is-italic">[2025-05-09]</span>
            <span class="news-text">åŒæµå¤§å­¦é«˜å±‚æ¬¡äººæ‰ç§‘ç ”é¡¹ç›®ç«‹é¡¹ï¼šæ•´åˆå¤§æ•°æ®ä¸å¤§æ¨¡å‹çš„ç©ºé—´è§„åˆ’æ™ºèƒ½æŠ€æœ¯ç ”ç©¶.</span>
          </div>
          <div class="news-item">
            <span class="date is-size-6 has-text-grey is-italic">[2025-05-01]</span>
            <span class="news-text">æ¬¢è¿ç‹ç¦ã€éƒ‘å®èˆŸåŠ å…¥å®éªŒå®¤ï¼Œæ”»è¯»åŸå¸‚è§„åˆ’åšå£«å’Œæ™ºèƒ½ç§‘å­¦ä¸æŠ€æœ¯åšå£«.</span>
          </div>
          <div class="news-item">
            <span class="date is-size-6 has-text-grey is-italic">[2025-04-15]</span>
            <span class="news-text">æ¬¢è¿å®‰æ«æ³“ï¼ŒæŸ¥æ€é½ï¼Œé‚“é—¯ï¼Œæç€šæ»¢åŠ å…¥å®éªŒå®¤ï¼Œæ”»è¯»ç¡•å£«ç ”ç©¶ç”Ÿ.</span>
          </div>
          <div class="news-item">
            <span class="date is-size-6 has-text-grey is-italic">[2025-01-14]</span>
            <span class="news-text">ä¸Šæµ·å¸‚æ•™å§”äººå·¥æ™ºèƒ½ä¿ƒè¿›ç§‘ç ”èŒƒå¼æ”¹é©èµ‹èƒ½å­¦ç§‘è·ƒå‡è®¡åˆ’é¡¹ç›®é‡ç‚¹é¡¹ç›®è·æ‰¹ç«‹é¡¹ï¼šæå‡ç©ºé—´è®¤çŸ¥å†³ç­–èƒ½åŠ›çš„åŸä¹¡è§„åˆ’å‚åŸŸå¤§æ¨¡å‹ç ”å‘.</span>
          </div>
          <div class="news-item">
            <span class="date is-size-6 has-text-grey is-italic">[2024-12-12]</span>
            <span class="news-text">2ä¸ªå¤§æ¨¡å‹ç›¸å…³é¡¹ç›®ï¼ˆä¸­è§„é™¢ã€æ·±åœ³æµ·ä¿ƒä¸­å¿ƒï¼‰é¡ºåˆ©å®Œæˆç»“é¢˜.</span>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->


<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
  <h1 class="title is-1 PlanGPT-1/1.5" id="PlanGPT-1/1.5">
    <span class="PlanGPT-1/1.5" style="vertical-align: middle">PlanGPT-1/1.5</span>
  </h1>
  </div>
</section>

<section class="section">
  <div class="container" style="margin-bottom: 2vh;">
    <div class="columns is-centered">
      <div class="column is-four-fifths has-text-centered">
        <h2 class="subtitle is-3 publication-subtitle" style="color: black; font-weight: bold;">
          PlanGPT: Enhancing Urban Planning with Tailored<br> Language Model and Efficient Retrieval
        </h2>
        <div class="column has-text-centered">
          <div class="publication-links">
            <!-- PDF Link. -->
            <span class="link-block">
              <!-- @PAN TODO: change links -->
              <a href="https://arxiv.org/abs/2402.19273"
                  class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                </span>
                <span>arXiv</span>
              </a>
            </span>
            <span class="link-block">
              <a href="https://behavioral-spatial-ai-lab.github.io/"
                  class="external-link button is-normal is-rounded is-dark">
                <span>ğŸ”—Homepage</span>
                </a>
            </span>
          </div>
        </div>
        <!-- <div class="has-text-right mt-4">
          <p class="post is-size-6 has-text-grey is-italic is_centered">
            Accepted by ACL Industry Track 2025(Oral)
          </p>
        </div> -->
        <h3 class="title is-4">Abstract</h3>
        <div class="content has-text-justified" style="line-height: 2;">
          <p>
            <!-- åœ¨åŸå¸‚è§„åˆ’é¢†åŸŸï¼Œé€šç”¨å¤§è¯­è¨€æ¨¡å‹é€šå¸¸æ— æ³•æ»¡è¶³è§„åˆ’å¸ˆçš„ç‰¹å®šéœ€æ±‚ã€‚ç”ŸæˆåŸå¸‚è§„åˆ’æ–‡æœ¬ã€æ£€ç´¢ç›¸å…³ä¿¡æ¯å’Œè¯„ä¼°è§„åˆ’æ–‡ä»¶ç­‰ä»»åŠ¡éƒ½å­˜åœ¨ç‹¬ç‰¹çš„æŒ‘æˆ˜ã€‚ä¸ºæé«˜åŸå¸‚ä¸“ä¸šäººå‘˜çš„æ•ˆç‡å¹¶å…‹æœè¿™äº›éšœç¢ï¼Œæˆ‘ä»¬æ¨å‡ºäº† PlanGPTï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªä¸“ä¸ºåŸå¸‚å’Œç©ºé—´è§„åˆ’é‡èº«å®šåˆ¶çš„ä¸“ä¸šè¯­è¨€æ¨¡å‹ã€‚é€šè¿‡ä¸ä¸­å›½åŸå¸‚è§„åˆ’ç ”ç©¶é™¢ç­‰æœºæ„çš„åä½œåŠªåŠ›ï¼ŒPlanGPTåˆ©ç”¨å®šåˆ¶çš„æœ¬åœ°æ•°æ®åº“æ£€ç´¢æ¡†æ¶ã€åŸºäºè¡Œä¸šçš„åŸºç¡€æ¨¡å‹å¾®è°ƒä»¥åŠå…ˆè¿›çš„å·¥å…·èƒ½åŠ›è¿›è¡Œå¼€å‘ã€‚å®è¯æµ‹è¯•è¯æ˜ï¼ŒPlanGPTå–å¾—äº†å…ˆè¿›çš„è¡¨ç°ï¼Œæä¾›ç²¾å‡†é€‚åº”åŸå¸‚è§„åˆ’ç»†èŠ‚çš„ä¼˜è´¨å“åº”ã€‚ -->
            In the field of urban planning, general-purpose large language models often fall short of meeting the specific needs of planners. Tasks such as generating urban planning texts, retrieving relevant information, and evaluating planning documents present unique challenges. To enhance the efficiency of urban professionals and overcome these obstacles, we introduce PlanGPT, the first specialized language model tailored for urban and spatial planning. Through collaborative efforts with institutions like the China Academy of Urban Planning and Design, PlanGPT is developed using a customized local database retrieval framework, industry-based foundational model fine-tuning, and advanced tool capabilities. Empirical testing demonstrates that PlanGPT achieves state-of-the-art performance, delivering high-quality responses that accurately adapt to the intricacies of urban planning.
          </p>
        </div>
        <h3 class="title is-4">Technical Architecture</h3>
          <div class="content has-text-justified">
            <img class="columns is-centered has-text-centered" src="./pictures/plangpt-architecture.png" alt="Teaser" width="95%"
                  style="margin:0 auto">
            <br>
            <figcaption>
              <p style="text-align: center;">
                <font color="061E61">
                    <b>Figure 1:</b> PlanGPT-1/1.5 Architecture.
                </font>
              </p>
            </figcaption>
          </div>
        <div class="content has-text-justified" style="line-height: 2;">
          <p>
            <!-- <b>PlanGPT-1.5ï¼š</b>åœ¨PlanGPT-1çš„åŸºç¡€ä¸Šï¼Œè¡¥å……äº†ä»åŸå¸‚è§„åˆ’å®åŠ¡ç•Œä¸šåŠ¡åœºæ™¯åº”ç”¨å¤§æ¨¡å‹çš„ç»éªŒã€è¿›ä¸€æ­¥ç¼“è§£å¹»è§‰çš„æ–¹æ³•ã€å‡å°‘äººå·¥æ ‡æ³¨æˆæœ¬çš„æ•°æ®åˆæˆæŠ€æœ¯æ¢ç´¢ç­‰å·¥ç¨‹è½åœ°å…³é”®æŠ€æœ¯ï¼Œè®ºæ–‡å·²è¢«ACL'25 (Industry) Oralæ¥æ”¶ï¼Œåœ¨å››ä¸ªreviewersä¸­æ”¶è·ä¸€ä¸ª9/10è¯„ä»·ï¼Œé«˜åº¦è®¤å¯äº†PlanGPTåœ¨è¡Œä¸šå¤§æ¨¡å‹ä¸­çš„ä»·å€¼ã€‚ -->
            <b>PlanGPT-1.5:</b> Building upon PlanGPT-1, it incorporates key engineering techniques for practical applications in the urban planning industry, including insights from real-world use cases, methods to further mitigate hallucinations, and data synthesis techniques to reduce manual annotation costs. The paper has been accepted by ACL'25 (Industry) Oral, receiving a 9/10 rating from one of the four reviewers, who highly recognized the value of PlanGPT in industry large models.
          </p>
          <blockquote>  
            â€œThe paper describes a real-life implementation of an LLM-based assistant tailored to a specific domain and highlights the importance of tailoring each component to obtain good usable results. It can serve as a reference for carrying out similar adaptations in other domains and use cases.â€
          </blockquote>
        </div>
        <div class="has-text-right mt-4">
          <p class="post is-size-6 has-text-grey is-italic">
            <!-- ğŸ“… å‘å¸ƒæ—¥æœŸï¼š2023å¹´9æœˆ28æ—¥ -->
            ğŸ“… Release Date: September 28, 2023
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
  <h1 class="title is-1 PlanGPT" id="PlanBenchè§„åˆ’çŸ¥è¯†åŸºå‡†">
    <span class="PlanGPT" style="vertical-align: middle">PlanBench Planning Knowledge Benchmark</span>
  </h1>
  </div>
</section>

<section class="section">
  <div class="container" style="margin-bottom: 2vh;">
    <div class="columns is-centered">
      <div class="column is-four-fifths has-text-centered">
        <h2 class="subtitle is-3 publication-subtitle" style="color: black; font-weight: bold;">
          A Comprehensive Benchmark for Evaluating Urban Planning Capabilities in Large Language Models
        </h2>
        <div class="column has-text-centered">
          <div class="publication-links">
            <!-- PDF Link. -->
            <!-- <span class="link-block">
              <a href="https://arxiv.org/"
                  class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                </span>
                <span>arXiv</span>
              </a>
            </span> -->
            <span class="link-block">
              <a href="https://behavioral-spatial-ai-lab.github.io/plangpt-bench/"
                  class="external-link button is-normal is-rounded is-dark">
                <span>ğŸ”—Homepage</span>
                </a>
            </span>
          </div>
        </div>
            <h3 class="title is-4">Abstract</h3>
            <div class="content has-text-justified" style="line-height: 2;">
            <p>
                <!-- åŸå¸‚è§„åˆ’ä½œä¸ºé«˜åº¦è·¨å­¦ç§‘ã€å®è·µå¯¼å‘å¼ºçš„é¢†åŸŸï¼Œå…¶æµ‹è¯•ä¸ä»…ä»…æ˜¯å¯¹çŸ¥è¯†çš„ç®€å•å›å¿†ï¼Œæ›´æ¶‰åŠå¤æ‚æƒ…å¢ƒåˆ¤æ–­ã€æ”¿ç­–ç†è§£ã€ç©ºé—´é€»è¾‘æ¨ç†ä¸ä»·å€¼è¯„ä¼°ã€‚è§„åˆ’ç±»æ–‡æœ¬å…·æœ‰æœ¯è¯­å¯†é›†ã€ç»“æ„å¤æ‚ã€æ¨ç†é“¾æ¡é•¿ç­‰ç‰¹ç‚¹ã€‚æ„å»ºbenchmarkæœ‰åŠ©äºæå‡å¤§æ¨¡å‹åœ¨ä»¥ä¸‹æ–¹é¢çš„è§„åˆ’é€‚é…èƒ½åŠ›ï¼š<br> -->
                Urban planning, as a highly interdisciplinary and practice-oriented field, requires not only simple recall of knowledge but also complex situational judgment, policy understanding, spatial logical reasoning, and value assessment. Planning texts are characterized by dense terminology, complex structures, and long reasoning chains. Constructing benchmarks can help enhance large models' planning adaptation capabilities in the following aspects:<br>
            </p>
                <!-- <ul>
                    <li>è§„åˆ’æ–‡æœ¬è§£æ„èƒ½åŠ›ï¼ˆå¦‚æ¡ä¾‹æ‹†è§£ã€æŒ‡æ ‡åˆ¤è¯»ï¼‰</li>
                    <li>å¤šå±‚çº§ç©ºé—´æ²»ç†é€»è¾‘èƒ½åŠ›ï¼ˆå›½å®¶-åŸå¸‚-ç¤¾åŒºï¼‰</li>
                    <li>æƒ…å¢ƒåŒ–æ”¿ç­–åˆ¤æ–­ä¸æ–¹æ¡ˆç”Ÿæˆèƒ½åŠ›ï¼ˆå¦‚é€‰å€ã€ç”¨åœ°é…ç½®ã€äº§ä¸šå»ºè®®ï¼‰</li>
                </ul> -->
                <ul>
                    <li>Deconstruction of planning texts (e.g., regulation breakdown, indicator interpretation)</li>
                    <li>Multi-level spatial governance logic (national - city - community)</li>
                    <li>Situational policy judgment and plan generation (e.g., site selection, land allocation, industry recommendations)</li>
                </ul>
            <p>
                <!-- æ–‡æœ¬ç±»benchmarkæ˜¯â€œå¤šæ¨¡æ€åŸå¸‚æ™ºèƒ½â€çš„è¯­è¨€åŸºç¡€ã€‚åœ¨åç»­ä¸åœ°å›¾ã€å›¾è¡¨ã€ç©ºé—´æ¨¡å‹çš„æ•´åˆä¸­ï¼Œæ–‡æœ¬ç†è§£èƒ½åŠ›æ˜¯å®Œæˆâ€œå›¾-æ–‡-ç­–â€ä¸‰ç»´è”åŠ¨çš„åŸºç¡€ç¯èŠ‚ã€‚<br> -->
                Text-based benchmarks serve as the linguistic foundation for "multimodal urban intelligence." In subsequent integrations with maps, charts, and spatial models, text comprehension capabilities are fundamental for achieving the three-dimensional linkage of "text-image-policy."
            </p>
            </div>
        <h3 class="title is-4">Technical Architecture</h3>
          <div class="content has-text-justified">
            <img class="columns is-centered has-text-centered" src="./pictures/planbench_text_show.png" alt="Teaser" width="95%"
                  style="margin:0 auto">
            <br>
            <figcaption>
              <p style="text-align: center;">
                <font color="061E61">
                    <b>Figure 2:</b> PlanBench-Text Architecture.
                </font>
              </p>
            </figcaption>
          </div>
        <div class="has-text-right mt-4">
          <p class="post is-size-6 has-text-grey is-italic">
            <!-- ğŸ“… å‘å¸ƒæ—¥æœŸï¼š2025å¹´5æœˆ19æ—¥ -->
            ğŸ“… Release Date: May 19, 2025
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
  <h1 class="title is-1 PlanGPT" id="PlanBenchè§„åˆ’å›¾è¯†åŸºå‡†">
    <!-- <span class="PlanGPT" style="vertical-align: middle">PlanBenchè§„åˆ’å›¾è¯†åŸºå‡†</span> -->
    <span class="PlanGPT" style="vertical-align: middle">PlanBench Planning Visual Recognition Benchmark</span>
  </h1>
  </div>
</section>

<section class="section">
  <div class="container" style="margin-bottom: 2vh;">
    <div class="columns is-centered">
      <div class="column is-four-fifths has-text-centered">
        <h2 class="subtitle is-3 publication-subtitle" style="color: black; font-weight: bold;">
          Multimodal Multi-image Understanding for Evaluating Multimodal Large Language Models
        </h2>
        <div class="column has-text-centered">
          <div class="publication-links">
            <!-- PDF Link. -->
            <!-- <span class="link-block">
              <a href="https://arxiv.org/"
                  class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                </span>
                <span>arXiv</span>
              </a>
            </span> -->
            <span class="link-block">
              <a href="https://behavioral-spatial-ai-lab.github.io/planvlm-bench/"
                  class="external-link button is-normal is-rounded is-dark">
                <span>ğŸ”—Homepage</span>
                </a>
            </span>
          </div>
        </div>
            <h3 class="title is-4">Abstract</h3>
            <div class="content has-text-justified" style="line-height: 2;">
              <!-- <p>
                  å›½åœŸç©ºé—´è§„åˆ’å›¾æ˜¯å°†å›½åœŸç©ºé—´è§„åˆ’çš„ç†å¿µã€ç›®æ ‡ã€ç­–ç•¥å’Œå…·ä½“æªæ–½ä»¥åœ°å›¾çš„å½¢å¼ç›´è§‚å±•ç¤ºå‡ºæ¥ï¼Œç”¨äºæŒ‡å¯¼å’Œåè°ƒå„ç±»å›½åœŸç©ºé—´å¼€å‘ã€ä¿æŠ¤å’Œåˆ©ç”¨æ´»åŠ¨ã€‚å®ƒä¸ä»…æ˜¯è§„åˆ’å†³ç­–çš„é‡è¦ä¾æ®ï¼Œä¹Ÿæ˜¯å…¬ä¼—å‚ä¸å’Œç›‘ç£è§„åˆ’å®æ–½çš„é‡è¦å·¥å…·ã€‚è§„åˆ’æ˜¯ç»¼åˆæ€§å’Œä¸“ä¸šæ€§æå¼ºçš„å·¥ä½œï¼Œå¦‚æœè¦è¯»é€è§„åˆ’å›¾çº¸ï¼Œä¸ä»…è¦æŠ“ä½ç²¾ç»†çš„å…ƒç´ ï¼ˆç¬¦å·ã€å›¾ä¾‹å’Œåœ°ç†è¦ç´ ç­‰ï¼‰ï¼Œè¿˜è¦æœ‰ç»“åˆæ”¿ç­–è¿›è¡Œç»¼åˆåˆ†æå’Œåˆ¤æ–­çš„èƒ½åŠ›ã€‚è¿™ç§å¤æ‚æ€§ä½¿å¾—è§„åˆ’å›¾çš„ç†è§£å…·æœ‰æŒ‘æˆ˜æ€§ã€‚éšç€å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰çš„å¿«é€Ÿå‘å±•ï¼Œæˆ‘ä»¬å»ºç«‹äº†å›½åœŸç©ºé—´è§„åˆ’å›¾çš„Benchmarkï¼Œä»¥è¯„ä¼°MLLMsåœ¨è§„åˆ’å›¾ç†è§£æ–¹é¢çš„èƒ½åŠ›ã€‚æˆ‘ä»¬çš„è´¡çŒ®å¦‚ä¸‹ï¼š<br>
                  <br>
                  <b>(1)	æ•°æ®ï¼š</b> æˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªä¸“å®¶æ ‡æ³¨çš„è§„åˆ’å›¾æ•°æ®åº“Spatial Planning Map Databaseï¼ˆSPMDï¼‰ï¼Œå…¶ç‰¹ç‚¹æ˜¯å¤šæ ·åŒ–çš„å›¾åƒå†…å®¹å’Œç”±è§„åˆ’é¢†åŸŸä¸“å®¶æä¾›çš„é«˜è´¨é‡æ ‡æ³¨ã€‚<br>
                  <b>(2)	æ¡†æ¶ï¼š</b> æˆ‘ä»¬æå‡ºäº†ä¸€å¥—åŸºäºè§„åˆ’å­¦ç§‘çš„ç»¼åˆæ ‡å‡†ï¼Œä»æ„ŸçŸ¥ã€æ¨ç†ã€å…³è”ã€åº”ç”¨å››ä¸ªè§’åº¦è¡¡é‡MLLMsçš„è§„åˆ’å›¾ç†è§£èƒ½åŠ›ï¼ŒåŒ…æ‹¬8ä¸ªç»†åˆ†ç±»åˆ«ã€‚<br>
                  <b>(3)	å®éªŒï¼š</b> é€šè¿‡åŸºäºæƒå¨é¢˜åº“ï¼ˆä¸­å›½æ³¨å†ŒåŸå¸‚è§„åˆ’å¸ˆæ‰§ä¸šèµ„æ ¼è€ƒè¯•å®åŠ¡é¢˜ç›®ï¼‰çŸ¥è¯†æ„å»ºçš„é—®ç­”ä»»åŠ¡ï¼Œæ˜¾è‘—é™ä½äº†æ¨¡å‹â€œå¹»è§‰å¼è§„èŒƒå¼•ç”¨â€çš„æ¯”ä¾‹ã€‚<br>
                  <b>(4)	ç»“æœï¼š</b> æ‰€æœ‰æ¨¡å‹åœ¨åº”ç”¨ç»´åº¦è¡¨ç°æœ€å·®ï¼ŒQwen2.5-VL-32B-Instruct å››ä¸ªç»´åº¦ç»¼åˆå¾—åˆ†æœ€é«˜ã€‚<br>
              </p> -->
              <p>
                  National spatial planning maps visually present the concepts, goals, strategies, and specific measures of spatial planning, serving as a guide for coordinating various spatial development, protection, and utilization activities. They are not only crucial for planning decisions but also important tools for public participation and oversight of planning implementation. Planning is a highly interdisciplinary and specialized task; understanding planning maps requires grasping detailed elements (symbols, legends, geographic features) and the ability to conduct comprehensive analysis and judgment in conjunction with policies. This complexity makes understanding planning maps challenging. With the rapid development of multimodal large language models (MLLMs), we have established a benchmark for national spatial planning maps to evaluate MLLMs' capabilities in understanding these maps. Our contributions are as follows:<br>
                  <br>
                  <b>(1) Data:</b> We constructed the Spatial Planning Map Database (SPMD), featuring diverse image content and high-quality annotations provided by experts in the field of planning.<br>
                  <b>(2) Framework:</b> We proposed a comprehensive framework based on planning disciplines, measuring MLLMs' understanding of planning maps from four perspectives: perception, reasoning, association, and application, including eight subcategories.<br>
                  <b>(3) Experiments:</b> By constructing question-answer tasks based on authoritative question banks (China's Registered Urban Planner Qualification Examination), we significantly reduced the proportion of "hallucination-style normative citations" by models.<br>
                  <b>(4) Results:</b> All models performed worst in the application dimension, with Qwen2.5-VL-32B-Instruct achieving the highest overall score across all four dimensions.<br>
            </div>
        <h3 class="title is-4">Technical Architecture</h3>
          <div class="content has-text-justified">
            <img class="columns is-centered has-text-centered" src="./pictures/VLMbench250512.png" alt="Teaser" width="95%"
                  style="margin:0 auto">
            <br>
            <figcaption>
              <p style="text-align: center;">
                <font color="061E61">
                    <b>Figure 3:</b> PlanBench-VL Architecture.
                </font>
              </p>
            </figcaption>
          </div>
        <div class="has-text-right mt-4">
          <p class="post is-size-6 has-text-grey is-italic">
            <!-- ğŸ“… å‘å¸ƒæ—¥æœŸï¼š2025å¹´5æœˆ19æ—¥ -->
            ğŸ“… Release Date: May 19, 2025
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
  <h1 class="title is-1 PlanGPT">
    <span class="PlanGPT" style="vertical-align: middle">PlanGPTåº”ç”¨</span>
  </h1>
  </div>
</section>

<section class="section">
  <div class="container" style="margin-bottom: 2vh;">
    <div class="columns is-centered">
      <div class="column is-four-fifths has-text-centered">
        <h2 class="subtitle is-3 publication-subtitle" style="color: black; font-weight: bold;">
          å ä¸ªå‘
        </h2>
      </div>
    </div>
  </div>
</section> -->

<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
  <h1 class="title is-1 PlanGPT" id="PlanGPT-VL">
    <span class="PlanGPT" style="vertical-align: middle">PlanGPT-VL</span>
  </h1>
  </div>
</section>

<section class="section">
  <div class="container" style="margin-bottom: 2vh;">
    <div class="columns is-centered">
      <div class="column is-four-fifths has-text-centered">
        <h2 class="subtitle is-3 publication-subtitle" style="color: black; font-weight: bold;">
          PlanGPT-VL: Enhancing Urban Planning with Domain-Specific Vision-Language Models
        </h2>
        <!-- <div class="has-text-right" style="display: flex; justify-content: center; margin: 2vh 0;">
          <div style="background-color: #f9f9f9; border-left: 4px solid #3273dc; padding: 1em 1.5em; border-radius: 8px; box-shadow: 0 2px 6px rgba(0,0,0,0.05); max-width: 800px; text-align: center;">
            <p class="is-size-6" style="font-style: normal; margin: 0; color: black; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'PingFang SC', 'Hiragino Sans GB', 'Microsoft YaHei', 'Helvetica Neue', sans-serif;">
              <a href="https://modelscope.cn/models/chichi56/plangpt-VL-10K" target="_blank">PlanGPT-VL</a>å·²æ­£å¼åœ¨Modelscopeå¹³å°å¼€æºï¼Œå¹¶åŒæ­¥å¼€æ”¾<a href="https://modelscope.cn/studios/chichi56/PlanGPT-VL/summary" target="_blank">æµ‹è¯•é€šé“</a>ï¼Œæ¬¢è¿è¯•ç”¨ä¸åé¦ˆã€‚
            </p>
          </div>
        </div> -->
        <div class="column has-text-centered">
          <div class="publication-links">
            <span class="link-block">
              <a href="https://arxiv.org/abs/2505.14481"
                  class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                </span>
                <span>arXiv</span>
              </a>
            </span>
            <span class="link-block">
                <a href="https://behavioral-spatial-ai-lab.github.io/plangpt-vl/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span>ğŸ”—Homepage</span>
                </a>
            </span>
            <span class="link-block">
              <a href="https://modelscope.cn/models/chichi56/plangpt-VL-10K/files"
                  class="external-link button is-normal is-rounded is-dark">
                <span>Model</span>
              </a>
            </span>
          </div>
        </div>
            <h3 class="title is-4">Abstract</h3>
            <div class="content has-text-justified" style="line-height: 2;">
              <p>
                <!-- å°½ç®¡åŸå¸‚è§„åˆ’åœ°å›¾å¯¹è§„åˆ’ä¸“ä¸šäººå‘˜å’Œæ•™è‚²å·¥ä½œè€…è‡³å…³é‡è¦ï¼Œä½†ç°æœ‰è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åœ¨è§£è¯»å’Œè¯„ä¼°è¿™ç±»ä¸“ä¸šåœ°å›¾æ—¶å¾€å¾€è¡¨ç°æ¬ ä½³ã€‚è¿™äº›è§„åˆ’åœ°å›¾é€šè¿‡å¯è§†åŒ–å‘ˆç°åœŸåœ°ç”¨é€”ã€åŸºç¡€è®¾æ–½å¸ƒå±€å’ŒåŠŸèƒ½åˆ†åŒºç­‰å…³é”®ä¿¡æ¯ï¼Œç†è§£å®ƒä»¬éœ€è¦ç‰¹å®šé¢†åŸŸçŸ¥è¯†ï¼Œè€Œæ™®é€šVLMsé€šå¸¸ç¼ºä¹è¿™ç§ä¸“ä¸šèƒ½åŠ›ã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å¼€å‘äº†PlanGPT-VLï¼Œè¿™æ˜¯é¦–ä¸ªä¸“ä¸ºåŸå¸‚è§„åˆ’åœ°å›¾è®¾è®¡çš„é¢†åŸŸç‰¹å®šè§†è§‰-è¯­è¨€æ¨¡å‹ï¼Œå…·æœ‰ä¸‰å¤§åˆ›æ–°ï¼š(1)PlanAnno-Væ¡†æ¶ï¼šç”¨äºç”Ÿæˆé«˜è´¨é‡è§„åˆ’åœ°å›¾è§†è§‰é—®ç­”æ•°æ®ï¼›(2)å…³é”®ç‚¹æ€ç»´æœºåˆ¶ï¼šé€šè¿‡ç»“æ„åŒ–éªŒè¯æ–¹æ³•æœ‰æ•ˆå‡å°‘æ¨¡å‹å¹»è§‰ï¼›(3)PlanBench-Vè¯„æµ‹åŸºå‡†ï¼šé¦–ä¸ªå…¨é¢è¯„ä¼°è§„åˆ’åœ°å›¾ç†è§£èƒ½åŠ›çš„ç³»ç»Ÿæµ‹è¯•æ ‡å‡†ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œä¸å¼€æºå’Œå•†ä¸šVLMsç›¸æ¯”ï¼ŒPlanGPT-VLåœ¨ä¸“ä¸šè§„åˆ’ä»»åŠ¡ä¸Šçš„å¹³å‡æ€§èƒ½æå‡äº†59.2%ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå°½ç®¡æˆ‘ä»¬çš„æ¨¡å‹ä»…æœ‰70äº¿å‚æ•°ï¼Œå±äºè½»é‡çº§è§„æ¨¡ï¼Œä½†å…¶è¡¨ç°å·²èƒ½åª²ç¾è¶…è¿‡720äº¿å‚æ•°çš„å¤§å‹æ¨¡å‹ï¼Œä¸ºåŸå¸‚è§„åˆ’å¸ˆæä¾›äº†ä¸€ä¸ªæ—¢å¯é åˆå…·é«˜äº‹å®å‡†ç¡®æ€§çš„ä¸“ä¸šåœ°å›¾åˆ†æå·¥å…·ã€‚<br> -->
                Despite the critical importance of urban planning maps to professionals and educators, existing vision-language models (VLMs) often struggle to interpret and evaluate these specialized maps. These planning maps visualize key information such as land use, infrastructure layout, and functional zoning, requiring domain-specific knowledge that general VLMs typically lack. To address this issue, we developed PlanGPT-VL, the first domain-specific vision-language model designed for urban planning maps, featuring three major innovations: (1) PlanAnno-V framework for generating high-quality visual question-answering data for planning maps; (2) Keypoint reasoning mechanism that effectively reduces model hallucinations through structured verification methods; (3) PlanBench-V evaluation benchmark, the first comprehensive testing standard for assessing understanding of planning maps. Experimental results show that compared to open-source and commercial VLMs, PlanGPT-VL achieves an average performance improvement of 59.2% on specialized planning tasks. Notably, despite having only 7 billion parameters, classifying it as a lightweight model, its performance rivals that of larger models with over 72 billion parameters, providing urban planners with a reliable and factually accurate tool for professional map analysis.
              </p>
            </div>
        <h3 class="title is-4">Technical Architecture</h3>
          <div class="content has-text-justified">
            <img class="columns is-centered has-text-centered" src="./pictures/planannoV.png" alt="Teaser" width="95%"
                  style="margin:0 auto">
            <br>
            <figcaption>
              <p style="text-align: center;">
                <font color="061E61">
                    <b>Figure 4:</b> PlanGPT-VL Architecture.
                </font>
              </p>
            </figcaption>
          </div>
        <div class="has-text-right mt-4">
          <p class="post is-size-6 has-text-grey is-italic">
            <!-- ğŸ“… å‘å¸ƒæ—¥æœŸï¼š2025å¹´5æœˆ19æ—¥ -->
            ğŸ“… Release Date: May 19, 2025
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
  <h1 class="title is-1 PlanGPT">
    <span class="PlanGPT" style="vertical-align: middle">ä¸Šæµ·é‡å­åŸå¸‚</span>
  </h1>
  </div>
</section>

<section class="section">
  <div class="container" style="margin-bottom: 2vh;">
    <div class="columns is-centered">
      <div class="column is-four-fifths has-text-centered">
        <h2 class="subtitle is-3 publication-subtitle" style="color: black; font-weight: bold;">
          å ä¸ªå‘
        </h2>
      </div>
    </div>
  </div>
</section> -->


<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
  <h1 class="title is-1 PlanGPT" id="æ•°æ®åˆæˆæŠ€æœ¯ç ”ç©¶">
    <!-- <span class="PlanGPT" style="vertical-align: middle">æ•°æ®åˆæˆæŠ€æœ¯ç ”ç©¶</span> -->
    <span class="PlanGPT" style="vertical-align: middle">Data Synthesis Techniques Research</span>
  </h1>
  </div>
</section>


<section class="section">
  <div class="container" style="margin-bottom: 2vh;">
    <div class="columns is-centered">
      <div class="column is-four-fifths has-text-centered">
        <h2 class="subtitle is-3 publication-subtitle" style="color: black; font-weight: bold;">
          FANNO: Augmenting High-Quality Instruction Data with Open-Sourced LLMs Only
        </h2>
        <div class="column has-text-centered">
          <div class="publication-links">
            <!-- PDF Link. -->
            <span class="link-block">
              <a href="https://arxiv.org/abs/2408.01323"
                  class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                </span>
                <span>arXiv</span>
              </a>
            </span>
            <span class="link-block">
              <a href="https://github.com/zhuchichi56/fanno.github.io"
                  class="external-link button is-normal is-rounded is-dark">
                <span>ğŸ”—Homepage</span>
                </a>
            </span>
          </div>
        </div>
        <div class="has-text-right mt-4">
          <p class="post is-size-6 has-text-grey is-italic is_centered">
            Accepted by ACL 2025 Findings
          </p>
        </div>
            <h3 class="title is-4">Abstract</h3>
            <div class="content has-text-justified" style="line-height: 2;">
              <p>
                <!-- æŒ‡ä»¤å¾®è°ƒä½œä¸ºåˆ©ç”¨å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æå‡ä»»åŠ¡æ€§èƒ½çš„é‡è¦è¿›å±•ï¼Œç„¶è€Œï¼ŒæŒ‡ä»¤æ•°æ®é›†çš„æ ‡æ³¨ä¼ ç»Ÿä¸Šæ˜¯ä¸€é¡¹æ—¢æ˜‚è´µåˆç¹ççš„è¿‡ç¨‹ï¼Œé€šå¸¸ä¾èµ–äºæ‰‹åŠ¨æ ‡æ³¨æˆ–æ˜‚è´µçš„ä¸“æœ‰LLM APIè°ƒç”¨ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†FANNOï¼Œä¸€ä¸ªå®Œå…¨è‡ªä¸»ä¸”å¼€æºçš„æ¡†æ¶ï¼Œå½»åº•é©æ–°äº†æ ‡æ³¨è¿‡ç¨‹ï¼Œæ— éœ€é¢„å…ˆå­˜åœ¨çš„æ ‡æ³¨æ•°æ®ã€‚FANNOåˆ©ç”¨Mistral-7b-instructæ¨¡å‹ï¼Œé€šè¿‡æ–‡æ¡£é¢„ç­›é€‰ã€æŒ‡ä»¤ç”Ÿæˆå’Œå“åº”ç”Ÿæˆç­‰ç»“æ„åŒ–è¿‡ç¨‹ï¼Œé«˜æ•ˆåœ°ç”Ÿæˆå¤šæ ·ä¸”é«˜è´¨é‡çš„æ•°æ®é›†ã€‚é€šè¿‡åœ¨Open LLM Leaderboardå’ŒAlpacaEvalåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒFANNOèƒ½å¤Ÿå…è´¹ç”Ÿæˆä¸äººå·¥æ ‡æ³¨æˆ–ç»è¿‡æ¸…ç†çš„æ•°æ®é›†ï¼ˆå¦‚Alpaca-GPT4-Cleanedï¼‰ç›¸å½“çš„é«˜è´¨é‡ã€å¤šæ ·æ€§å’Œå¤æ‚åº¦çš„æ•°æ®ã€‚ -->
                Instruction fine-tuning has emerged as a significant advancement in leveraging large language models (LLMs) to enhance task performance. However, the annotation of instruction datasets has traditionally been an expensive and labor-intensive process, often relying on manual labeling or costly proprietary LLM API calls. To address these challenges, we introduce FANNO, a fully autonomous and open-source framework that revolutionizes the annotation process without requiring pre-existing labeled data. FANNO efficiently generates diverse and high-quality datasets through structured processes such as document pre-filtering, instruction generation, and response generation using the Mistral-7b-instruct model. Experimental results on the Open LLM Leaderboard and AlpacaEval benchmarks demonstrate that FANNO can generate high-quality, diverse, and complex data comparable to human annotations
              </p>
            </div>
        <h3 class="title is-4">Technical Architecture</h3>
          <div class="content has-text-justified">
            <img class="columns is-centered has-text-centered" src="./pictures/fanno.png" alt="Teaser" width="95%"
                  style="margin:0 auto">
            <br>
            <figcaption>
              <p style="text-align: center;">
                <font color="061E61">
                    <b>Figure 5:</b> FANNO Architecture.
                </font>
              </p>
            </figcaption>
          </div>
        <div class="has-text-right mt-4">
          <p class="post is-size-6 has-text-grey is-italic">
            <!-- ğŸ“… å‘å¸ƒæ—¥æœŸï¼š2024å¹´8æœˆ2æ—¥ -->
            ğŸ“… Release Date: August 2, 2024
          </p>
        </div>
        <!-- åˆ†å‰²çº¿ -->
        <hr style="border: 1px solid #ddd; margin: 40px 0;">
        
        <h2 class="subtitle is-3 publication-subtitle" style="color: black; font-weight: bold;">
          Tag-Instruct: Controlled Instruction Complexity Enhancement through Structure-based Augmentation
        </h2>
        <div class="column has-text-centered">
          <div class="publication-links">
            <!-- PDF Link. -->
            <span class="link-block">
              <a href="https://github.com/sustech-nlp/Tag-Instruct/blob/main/tag_instruct_acl25_arixv.pdf"
                  class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                </span>
                <span>PDF</span>
              </a>
            </span>
            <span class="link-block">
              <a href="https://github.com/sustech-nlp/Tag-Instruct"
                  class="external-link button is-normal is-rounded is-dark">
                <span>ğŸ”—Homepage</span>
                </a>
            </span>
          </div>
        </div>
        <div class="has-text-right mt-4">
          <p class="post is-size-6 has-text-grey is-italic is_centered">
            Accepted by ACL 2025 Findings
          </p>
        </div>
            <h3 class="title is-4">Abstract</h3>
            <div class="content has-text-justified" style="line-height: 2;">
              <p>
                <!-- é«˜è´¨é‡çš„æŒ‡ä»¤æ•°æ®å¯¹å¼€å‘å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è‡³å…³é‡è¦ï¼Œä½†ç°æœ‰æ–¹æ³•åœ¨æœ‰æ•ˆæ§åˆ¶æŒ‡ä»¤å¤æ‚åº¦æ–¹é¢å­˜åœ¨å›°éš¾ã€‚æˆ‘ä»¬æå‡ºäº†TAG-INSTRUCTï¼Œè¿™æ˜¯ä¸€ä¸ªé€šè¿‡ç»“æ„åŒ–è¯­ä¹‰å‹ç¼©å’Œå—æ§éš¾åº¦å¢å¼ºæ¥æå‡æŒ‡ä»¤å¤æ‚åº¦çš„æ–°æ¡†æ¶ã€‚ä¸ä»¥å‰åŸºäºæç¤ºçš„æ–¹æ³•ï¼ˆç›´æ¥å¤„ç†åŸå§‹æ–‡æœ¬ï¼‰ä¸åŒï¼ŒTAG-INSTRUCTå°†æŒ‡ä»¤å‹ç¼©åˆ°ä¸€ä¸ªç´§å‡‘çš„æ ‡ç­¾ç©ºé—´ï¼Œå¹¶é€šè¿‡å¼ºåŒ–å­¦ä¹ å¼•å¯¼çš„æ ‡ç­¾æ‰©å±•ç³»ç»Ÿåœ°å¢å¼ºå¤æ‚åº¦ã€‚é€šè¿‡å¹¿æ³›çš„å®éªŒï¼Œæˆ‘ä»¬å±•ç¤ºäº†TAG-INSTRUCTåœ¨æŒ‡ä»¤å¤æ‚åº¦å¢å¼ºæ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚æˆ‘ä»¬çš„åˆ†æè¡¨æ˜ï¼Œåœ¨æ ‡ç­¾ç©ºé—´ä¸­æ“ä½œæä¾›äº†æ›´ä¼˜çš„å¯æ§æ€§å’Œç¨³å®šæ€§ï¼Œé€‚ç”¨äºä¸åŒçš„æŒ‡ä»¤åˆæˆæ¡†æ¶ã€‚ -->
                High-quality instruction data is crucial for developing large language models (LLMs), yet existing methods struggle to effectively control instruction complexity. We introduce TAG-INSTRUCT, a novel framework that enhances instruction complexity through structured semantic compression and controlled difficulty augmentation. Unlike previous prompt-based approaches that directly handle raw text, TAG-INSTRUCT compresses instructions into a compact tag space and systematically enhances complexity through a reinforcement learning-guided tag expansion. Through extensive experiments, we demonstrate that TAG-INSTRUCT outperforms existing methods in instruction complexity enhancement. Our analysis indicates that operating within the tag space provides superior controllability and stability, making it suitable for various instruction synthesis frameworks.
              </p>
            </div>
        <h3 class="title is-4">Technical Architecture</h3>
          <div class="content has-text-justified">
            <img class="columns is-centered has-text-centered" src="./pictures/tag-instruct.png" alt="Teaser" width="95%"
                  style="margin:0 auto">
            <br>
            <figcaption>
              <p style="text-align: center;">
                <font color="061E61">
                    <b>Figure 6:</b> Tag-Instruct Architecture.
                </font>
              </p>
            </figcaption>
          </div>
        <div class="has-text-right mt-4">
          <p class="post is-size-6 has-text-grey is-italic">
            <!-- ğŸ“… å‘å¸ƒæ—¥æœŸï¼š2025å¹´5æœˆ8æ—¥ -->
            ğŸ“… Release Date: May 8, 2025
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
  <h1 class="title is-1 PlanGPT" id="ç±»è„‘ç©ºé—´æ™ºèƒ½ï¼šä½ç½®ç¼–ç èµ‹èƒ½å¤§æ¨¡å‹">
    <!-- <span class="PlanGPT" style="vertical-align: middle">ç±»è„‘ç©ºé—´æ™ºèƒ½ï¼šä½ç½®ç¼–ç èµ‹èƒ½å¤§æ¨¡å‹</span> -->
    <span class="PlanGPT" style="vertical-align: middle">Brain-inspired Spatial Intelligence: Positional Encoding Empowering Large Models</span>
  </h1>
  </div>
</section>

<section class="section">
  <div class="container" style="margin-bottom: 2vh;">
    <div class="columns is-centered">
      <div class="column is-four-fifths has-text-centered">
        <h2 class="subtitle is-3 publication-subtitle" style="color: black; font-weight: bold;">
          GridPE: Unifying Positional Encoding in Transformers with a Grid Cell-Inspired Framework
        </h2>
        <div class="column has-text-centered">
          <div class="publication-links">
            <!-- PDF Link. -->
            <span class="link-block">
              <a href="https://arxiv.org/abs/2406.07049"
                  class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                </span>
                <span>arXiv</span>
              </a>
            </span>
            <!-- <span class="link-block">
              <a href="https://wangqianxu7.github.io/demo_show/"
                  class="external-link button is-normal is-rounded is-dark">
                <span>ğŸ”—ä¸»é¡µ</span>
                </a>
            </span> -->
          </div>
        </div>
            <h3 class="title is-4">Abstract</h3>
            <div class="content has-text-justified" style="line-height: 2;">
              <p>
                <!-- ç†è§£ç©ºé—´ä½ç½®å’Œå…³ç³»æ˜¯ç°ä»£äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„åŸºæœ¬èƒ½åŠ›ã€‚äººç±»ç©ºé—´è®¤çŸ¥çš„ç ”ç©¶ä¸ºè¿™ä¸€é¢†åŸŸæä¾›äº†å®è´µçš„æŒ‡å¯¼ã€‚ç¥ç»ç§‘å­¦çš„å‘ç°çªå‡ºäº†ç½‘æ ¼ç»†èƒåœ¨ç©ºé—´è¡¨å¾ä¸­çš„é‡è¦ä½œç”¨ï¼ŒåŒ…æ‹¬è·ç¦»è®¡ç®—ã€è·¯å¾„æ•´åˆå’Œå°ºåº¦è¾¨è¯†ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ç§æ–°é¢–çš„ä½ç½®ç¼–ç æ–¹æ¡ˆï¼Œçµæ„Ÿæ¥æºäºå‚…é‡Œå¶åˆ†æä»¥åŠæœ€æ–°çš„è®¡ç®—ç¥ç»ç§‘å­¦å…³äºç½‘æ ¼ç»†èƒçš„ç ”ç©¶æˆæœã€‚å‡è®¾ç½‘æ ¼ç»†èƒé€šè¿‡å‚…é‡Œå¶åŸºå‡½æ•°çš„æ€»å’Œæ¥ç¼–ç ç©ºé—´ä½ç½®ï¼Œæˆ‘ä»¬å±•ç¤ºäº†åœ¨å†…ç§¯è®¡ç®—è¿‡ç¨‹ä¸­ï¼Œç½‘æ ¼è¡¨ç¤ºå…·æœ‰å¹³ç§»ä¸å˜æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åŸºäºç”Ÿç‰©å­¦æ•ˆç‡åŸç†æ¨å¯¼å‡ºäº†å¤šç»´æ¬§å‡ é‡Œå¾—ç©ºé—´çš„æœ€ä¼˜ç½‘æ ¼å°ºåº¦æ¯”ç‡ã€‚åˆ©ç”¨è¿™äº›è®¡ç®—åŸç†ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§å—ç½‘æ ¼ç»†èƒå¯å‘çš„ä½ç½®ç¼–ç æŠ€æœ¯ï¼Œç§°ä¸ºGridPEï¼Œç”¨äºé«˜ç»´ç©ºé—´ä¸­çš„ä½ç½®ç¼–ç ã€‚æˆ‘ä»¬å°†GridPEé›†æˆåˆ°é‡‘å­—å¡”è§†è§‰å˜æ¢å™¨æ¶æ„ä¸­ã€‚æˆ‘ä»¬çš„ç†è®ºåˆ†æè¡¨æ˜ï¼ŒGridPEä¸ºä»»æ„é«˜ç»´ç©ºé—´ä¸­çš„ä½ç½®ç¼–ç æä¾›äº†ç»Ÿä¸€çš„æ¡†æ¶ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒGridPEæ˜¾è‘—æå‡äº†å˜æ¢å™¨çš„æ€§èƒ½ï¼Œå¼ºè°ƒäº†å°†ç¥ç»ç§‘å­¦æ´å¯ŸåŠ›èå…¥äººå·¥æ™ºèƒ½ç³»ç»Ÿè®¾è®¡çš„é‡è¦æ€§ã€‚ -->
                Understanding spatial positions and relationships is a fundamental capability of modern AI systems. Research on human spatial cognition provides valuable guidance in this area. Discoveries in neuroscience highlight the crucial role of grid cells in spatial representation, including distance computation, path integration, and scale discrimination. This paper introduces a novel positional encoding scheme inspired by Fourier analysis and recent computational neuroscience findings on grid cells. Assuming that grid cells encode spatial positions as a sum of Fourier basis functions, we demonstrate that grid representations exhibit translational invariance during inner product computations. Furthermore, we derive the optimal grid scale ratio for multi-dimensional Euclidean spaces based on principles of biological efficiency. Leveraging these computational principles, we develop a grid cell-inspired positional encoding technique called GridPE for high-dimensional space encoding. We integrate GridPE into pyramid vision transformer architectures. Our theoretical analysis shows that GridPE provides a unified framework for positional encoding in arbitrary high-dimensional spaces. Experimental results indicate that GridPE significantly enhances transformer performance, emphasizing the importance of incorporating neuroscientific insights into AI system design.
              </p>
            </div>
        <h3 class="title is-4">Technical Architecture</h3>
          <div class="content has-text-justified">
            <img class="columns is-centered has-text-centered" src="./pictures/GridPE.png" alt="Teaser" width="95%"
                  style="margin:0 auto">
            <br>
            <figcaption>
              <p style="text-align: center;">
                <font color="061E61">
                    <b>Figure 7:</b> GridPE Architecture.
                </font>
              </p>
            </figcaption>
          </div>
        <div class="has-text-right mt-4">
          <p class="post is-size-6 has-text-grey is-italic">
            <!-- ğŸ“… å‘å¸ƒæ—¥æœŸï¼š2024å¹´6æœˆ11æ—¥ -->
            ğŸ“… Release Date: June 11, 2024
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
  <h1 class="title is-1 PlanGPT", id="ç”Ÿæ´»åœˆå¤§æ¨¡å‹">
    <!-- <span class="PlanGPT" style="vertical-align: middle">ç”Ÿæ´»åœˆå¤§æ¨¡å‹</span> -->
    <span class="PlanGPT" style="vertical-align: middle">Life Circle Large Model</span>
  </h1>
  </div>
</section>

<section class="section">
  <div class="container" style="margin-bottom: 2vh;">
    <div class="columns is-centered">
      <div class="column is-four-fifths has-text-centered">
        <h2 class="subtitle is-3 publication-subtitle" style="color: black; font-weight: bold;">
          Large Language Models Empowering Community Life Circle Planning and Governance Research
        </h2>
        <div class="has-text-right mt-4">
          <p class="post is-size-6 has-text-grey is-italic is_centered">
            <!-- å³å°†åˆŠç™»åœ¨ã€Šä¸Šæµ·åŸå¸‚è§„åˆ’ã€‹ -->
            To be published in ã€ŠShanghai City Planningã€‹
          </p>
        </div>
            <!-- <div class="column has-text-centered">
              <img class="columns is-centered has-text-centered" src="./pictures/æ–¹å…ƒé—®é—®.png" alt="Teaser" width="65%"
                      style="margin:0 auto">
            </div> -->
        <h3 class="title is-4">Abstract</h3>
          <div class="content has-text-justified" style="line-height: 2;">
            <p>
              <!-- å›´ç»•ç”Ÿæ´»åœˆè§„åˆ’ä¸ç¤¾åŒºæ²»ç†ï¼ŒLLM å¯åœ¨ä»¥ä¸‹å…³é”®ç¯èŠ‚ä¸­å‘æŒ¥èµ‹èƒ½ä½œç”¨ã€‚é¦–å…ˆï¼Œé€šè¿‡è‡ªç„¶è¯­è¨€äº¤äº’ï¼ŒLLM å¯ç†è§£å±…æ°‘åœ¨ä¸åŒæƒ…å¢ƒä¸‹çš„çœŸå®è¯‰æ±‚ï¼Œè‡ªåŠ¨ä»èŠå¤©è®°å½•ã€é—®å·æ–‡æœ¬ã€ç¤¾äº¤å¹³å°è¯„è®ºä¸­æå–éœ€æ±‚ä¸»é¢˜ä¸æƒ…æ„Ÿå€¾å‘ï¼Œå®ç°éœ€æ±‚çš„è‡ªåŠ¨å½’ç±»ä¸ä¼˜å…ˆçº§æ’åºï¼Œç ´è§£å±…æ°‘éœ€æ±‚å¼‚è´¨æ€§é«˜ä¸è¡¨è¾¾æ–¹å¼éç»“æ„åŒ–ä¹‹é—´çŸ›ç›¾æ‰€å¸¦æ¥çš„ç²¾å‡†æœåŠ¡ä¾›ç»™å›°éš¾ã€‚å…¶æ¬¡ï¼ŒLLM èƒ½å¤Ÿå°†æ¥è‡ªä¼ æ„Ÿå™¨ç½‘ç»œã€ç¤¾åŒºGISã€äººå£ç»Ÿè®¡ã€æ”¿åŠ¡æœåŠ¡å¹³å°ç­‰çš„æ•°æ®è¿›è¡Œè¯­ä¹‰æ•´åˆä¸å…³ç³»å»ºæ¨¡ï¼Œæå‡æ•°æ®é—´çš„å¯è§£é‡Šæ€§ä¸å¯æ“ä½œæ€§ï¼Œä¸ºç”Ÿæ´»åœˆçš„åŠŸèƒ½è¯„ä¼°ã€èµ„æºé…ç½®ä¸ç©ºé—´ä¼˜åŒ–æä¾›æ”¯æ’‘ã€‚åŒæ—¶ï¼Œåœ¨ç¤¾åŒºååŒæ²»ç†è¿‡ç¨‹ä¸­ï¼ŒLLM å¯å……å½“â€œä¸­ä»‹æ™ºèƒ½ä½“â€ï¼Œæ”¯æŒå±…æ°‘ä¸è¡—é“åŠã€ç‰©ä¸šã€ä¼ä¸šç­‰å¤šå…ƒä¸»ä½“ä¹‹é—´çš„è¯­ä¹‰æ¡¥æ¥ï¼Œè¾…åŠ©å®Œæˆæ”¿ç­–è§£é‡Šã€è®®é¢˜åå•†ã€å…±è¯†ç”Ÿæˆç­‰è¿‡ç¨‹ï¼Œæå‡ååŒæ•ˆç‡ä¸æ»¡æ„åº¦ã€‚ -->
              In the context of life circle planning and community governance, large language models (LLMs) can play a pivotal role in several key areas. Firstly, through natural language interaction, LLMs can understand residents' genuine needs in various contexts, automatically extracting demand themes and sentiment tendencies from chat records, survey texts, and social media comments. This enables automatic categorization and prioritization of demands, addressing the challenges of high heterogeneity in resident needs and unstructured expression methods, thus facilitating precise service provision. Secondly, LLMs can semantically integrate and model relationships among data from sensor networks, community GIS, demographic statistics, and government service platforms, enhancing the interpretability and operability of data. This supports functional assessment, resource allocation, and spatial optimization of life circles. Additionally, in the process of collaborative community governance, LLMs can act as "intermediary agents," facilitating semantic bridging between residents and diverse entities such as street offices, property management, and enterprises. They assist in policy interpretation, topic negotiation, consensus generation, and other processes, thereby improving collaboration efficiency and satisfaction.
            </p>
          </div>
        <h3 class="title is-4">Technical Architecture</h3>
          <div class="columns is-centered">
            <div class="column is-narrow has-text-centered">
              <img src="./pictures/grid_rag.png" alt="Teaser" width="85%" style="margin: 0 auto;">
              <figcaption>
                <p style="text-align: center;">
                  <!-- <font color="061E61"><b>Figure 8:</b> åœ°ç†é‚»è¿‘æ€§å¢å¼ºçš„å¤šæ¨¡æ€RAGæ¡†æ¶.</font> -->
                  <font color="061E61"><b>Figure 8:</b> Geography Proximity Enhanced Multimodal RAG Framework.</font>
                </p>
              </figcaption>
            </div>
          </div>
          <div class="content has-text-justified" style="line-height: 2;">
            <p>
              <!-- ç”±å®éªŒå®¤æåšæ´‹ä¸é»„è¯ºè´¤ç ”å‘çš„å¾®ä¿¡å°ç¨‹åºâ€œæ–¹å…ƒé—®é—®â€éƒ¨åˆ†å®ç°äº†ä¸Šè¿°å¤§æ¨¡å‹åŠ©ç†ç”Ÿæ´»åœˆè§„åˆ’ä¸æ²»ç†çš„åœºæ™¯ï¼Œèšç„¦åœ¨é’ˆå¯¹ç¤¾åŒºå±…æ°‘å’Œå•†å®¶çš„å…¬å…±æœåŠ¡è®¾æ–½ä¿¡æ¯æ™ºèƒ½åŠ©æ‰‹ï¼Œç›®å‰å·²ç»åœ¨æ·±åœ³å¸‚å—å¤´å¤åŸç¤¾åŒºå±•å¼€è¯•è¿è¡Œä¸è½åœ°å®éªŒã€‚è¯¥åº”ç”¨é€šè¿‡å¾®ä¿¡å°ç¨‹åºçš„è‡ªç„¶è¯­è¨€äº¤äº’ï¼Œç»“åˆç¤¾åŒºçš„åœ°ç†ä¿¡æ¯ä¸å¤šæ¨¡æ€æ•°æ®ï¼Œå®ç°äº†å¯¹ç¤¾åŒºå…¬å…±æœåŠ¡è®¾æ–½çš„æ™ºèƒ½æŸ¥è¯¢ä¸æ¨èï¼Œä¸ºç¤¾åŒºå±…æ°‘æä¾›äº†ä¾¿æ·çš„æœåŠ¡å¯¼èˆªä¸å’¨è¯¢ã€‚åŒæ—¶ï¼Œè¯¥åº”ç”¨è¿˜æ”¯æŒç¤¾åŒºå±…æ°‘ä¸å•†å®¶ä¹‹é—´çš„ä¿¡æ¯å…±äº«ä¸äº¤æ˜“ï¼Œä¸ºç¤¾åŒºçš„å…¬å…±æœåŠ¡è®¾æ–½ç®¡ç†ä¸è¿è¥æä¾›äº†æ”¯æŒã€‚<br> -->
              The WeChat mini-program "æ–¹å…ƒé—®é—®" (Fangyuan Wenwen), developed by our lab members Li Boyang and Huang Nuoxian, partially implements the scenarios of large model-assisted life circle planning and governance. It focuses on providing an intelligent assistant for public service facility information for community residents and businesses, and has been piloted in the Nantou Ancient City community in Shenzhen. This application utilizes natural language interaction through the WeChat mini-program, combined with community geographic information and multimodal data, to enable intelligent querying and recommendation of community public service facilities, providing residents with convenient service navigation and consultation. Additionally, it supports information sharing and transactions between community residents and businesses, aiding in the management and operation of public service facilities in the community.
            </p>
          </div>
          <img class="columns is-centered has-text-centered" src="./pictures/fangyuanwenwen.png" alt="Teaser" width="75%"
                  style="margin:0 auto">
            <figcaption>
              <p style="text-align: center;">
                <font color="061E61">
                    <!-- <b>Figure 9:</b> â€œæ–¹å…ƒé—®é—®â€ç¤¾åŒºåº”ç”¨åœºæ™¯ç¤ºä¾‹. -->
                    <b>Figure 9:</b> Example of "Fangyuan Wenwen" Community Application Scenario.
                </font>
              </p>
            </figcaption>
        <div class="has-text-right mt-4">
          <p class="post is-size-6 has-text-grey is-italic">
            <!-- ğŸ“… å‘å¸ƒæ—¥æœŸï¼š2024å¹´8æœˆ26æ—¥ -->
            ğŸ“… Release Date: August 26, 2024
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<style>
  .image-row {
      display: center; /* Use flexbox layout */
  }
  .image-row img {
      width: 40%; /* Each image takes up 50% of the width */
  }
</style>

<div class="container mt-6">
  <div class="content">
    <h3 class="title is-4">Members</h3>
    <div class="thanks-content" style="width: 100%;">
      <div class="thanks-text" style="line-height: 3;">
        <p style="font-size: 16px;">
          <!-- æœ±èµ«ï¼Œé™ˆæ—»æ­†ï¼Œé‚“å¥•æ°ï¼Œè‹å†›åˆï¼Œç‹ç¨³ï¼Œç‹é›¨æ¶¦ï¼Œæ­¦é’°æ—ï¼Œç‰›å½©æ¾„ï¼Œé™†å¤©åï¼Œåˆ˜ç¨‹ç¨‹ï¼Œæåšæ´‹ï¼Œé»„è¯ºè´¤ï¼Œè”¡è¿å„¿ï¼Œé­ç¥ï¼Œæ¨æ€æ­£ï¼Œç‰›ç’ç‘¶ï¼Œé¡¾å˜‰é’°ï¼Œé‚¹å®‡æ™—ï¼Œå®‰æ«æ³“ï¼ŒæŸ¥æ€é½ï¼Œé‚“é—¯ï¼Œæç€šæ»¢ï¼Œéƒ‘å®èˆŸï¼Œç‹ç¦ -->
          He Zhu, Minxin Chen, Yijie Deng, Junyou Su, Wen Wang, Yurun Wang, Yulin Wu, Caicheng Niu, Tianhua Lu, Chengcheng Liu, Boyang Li, Nuoxian Huang, Ying'er Cai, Yue Wei, Sizheng Yang, Luyao Niu, Jiayu Gu, Yuhan Zou, Fenghong An, Siqi Cha, Chuang Deng, Hanying Li, Hongzhou Zheng and Qi Wang.
        </p>
      </div>
    </div>
    <div class="image-container" style="display: flex; flex-wrap: wrap; justify-content: center; gap: 30px; align-items: center;">
      <div class="thanks-image" style="flex: 1 1 200px; max-width: 300px;">
        <img src="./pictures/BSAI.png" alt="BSAI" style="width: 100%; height: auto; object-fit: contain;">
      </div>
      <div class="thanks-image" style="flex: 1 1 200px; max-width: 300px;">
        <img src="./pictures/caup.png" alt="CAUP" style="width: 100%; height: auto; object-fit: contain;">
      </div>
    </div>
  </div>
</div>




<!-- @PAN TODO: bibtex -->
<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title is-3 has-text-centered">BibTeX</h2>
    <pre><code>
      @misc{meng2024PlanGPTmultimodalmultiimageunderstanding,
        title={PlanGPT: Multimodal Multi-image Understanding for Evaluating Large Vision-Language Models}, 
        author={Fanqing Meng and Jin Wang and Chuanhao Li and Quanfeng Lu and Hao Tian and Jiaqi Liao and Xizhou Zhu and Jifeng Dai and Yu Qiao and Ping Luo and Kaipeng Zhang and Wenqi Shao},
        year={2024},
        eprint={2408.02718},
        archivePrefix={arXiv},
        primaryClass={cs.CV},
        url={https://arxiv.org/abs/2408.02718}, 
  }
</code></pre>
  </div>
</section> -->

<!-- <footer class="footer" style="height: 50px; padding-top: 0px; padding-bottom: 0px;">
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is website adapted from <a href="https://github.com/OpenGVLab/MMT-Bench">MMT-Bench</a>, <a href="https://mmmu-benchmark.github.io/">MMMU</a>, <a href="https://mathvista.github.io/">MathVista</a> and <a href="https://nerfies.github.io/">Nerfies</a>, licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>

</footer> -->

<style>
  .hidden {
      display: none;
  }
  .sortable:hover {
      cursor: pointer;
  }
  .asc::after {
      content: ' â†‘';
  }
  .desc::after {
      content: ' â†“';
  }

  h1.maintitle {
    font-size: 2.5rem !important; /* å¤§æ ‡é¢˜ */
    font-weight: bold;
    color:black;
  }

  .center {
    display: block;
    margin-left: auto;
    margin-right: auto;
    width: 80%;
  }

  .publication-links .link-block {
    margin: 0 0.5rem;
    display: inline-block;
  }
  #toggleButton {
    background-color: #ffffff;
    border: 1px solid #dddddd;
    color: #555555;
    padding: 10px 20px;
    text-align: center;
    text-decoration: none;
    display: inline-block;
    font-size: 14px;
    margin: 4px 2px;
    cursor: pointer;
    border-radius: 25px; 
    box-shadow: 0 4px 8px 0 rgba(0,0,0,0.2);
    transition-duration: 0.4s;
  }

  #toggleButton:hover {
    box-shadow: 0 12px 16px 0 rgba(0,0,0,0.24), 0 17px 50px 0 rgba(0,0,0,0.19); /* é¼ æ ‡æ‚¬åœæ—¶çš„é˜´å½±æ•ˆæœ */
  }

  table {
    border-collapse: collapse;
    width: 100%;
    margin-top: 5px;
    border: 1px solid #ddd;
    font-size: 14px;
  }

  th, td {
      text-align: left;
      padding: 8px;
  }

  th {
      background-color: #f2f2f2;
      border-bottom: 2px solid #ddd;
  }

  td:hover {background-color: #ffffff;}

.thanks-content {
  display: flex;
  justify-content: space-between;
  align-items: center;
  flex-wrap: wrap; /* å…è®¸åœ¨å°å±å¹•è‡ªåŠ¨æ¢è¡Œ */
  gap: 20px; /* ä¿æŒå…ƒç´ ä¹‹é—´çš„é—´è· */
}

.thanks-text {
  max-width: calc(100% - 120px); /* å›¾ç‰‡å®½åº¦+é—´è· */
  flex: 1 1 300px; /* æ–‡å­—å®¹å™¨ä¹Ÿå…·æœ‰å¼¹æ€§ */
}

.thanks-image img {
  width: 400px;
  height: auto;
}

/* ---------- æ‰‹æœºç«¯æ ·å¼ ---------- */
@media screen and (max-width: 768px) {
  .thanks-content {
    flex-direction: column; /* å‚ç›´æ’åˆ—æ–‡å­—å’Œå›¾ç‰‡ */
    align-items: flex-start; /* å·¦å¯¹é½å†…å®¹ */
    gap: 1px; /* å‡å°é—´è· */
  }

  .thanks-text {
    max-width: 100%;
    width: 100%;
  }

  .thanks-image img {
    width: 100%;
    max-width: 100%;
    height: auto;
  }

  h1.title{
    font-size: 1.5rem !important; /* æ‰‹æœºç«¯æ›´å°å­—ä½“ï¼Œæ›´é€‚åˆé˜…è¯» */
    font-weight: bold;
  }
  
  h1.maintitle{
    font-size: 1.9rem !important; /* æ‰‹æœºç«¯æ›´å°å­—ä½“ï¼Œæ›´é€‚åˆé˜…è¯» */
    font-weight: bold;
    color:black;
  }

  h2.publication-subtitle {
    font-size: 1.2rem !important; /* æ‰‹æœºç«¯æ›´å°å­—ä½“ï¼Œæ›´é€‚åˆé˜…è¯» */
    font-weight: bold;
  }

  h1 {
    font-size: 1.2rem;
  }

  h2{
    font-size: 1rem;
  }
  
  .news-item {
    display: flex;
    align-items: baseline;
    margin-bottom: 8px;
    gap: 3px;
  }

  .date {
    flex: 0 0 15%; /* å›ºå®šå 15%å®½åº¦ */
    white-space: nowrap;
    display: inline !important;
    margin-bottom: 0 !important;
    font-size: 0.8rem !important;
  }

  .news-text {
    flex: 1 1 85%; /* å 85%ï¼Œå…è®¸æ¢è¡Œ */
    word-break: break-word;
    display: inline !important;
    margin-bottom: 0 !important;
    font-size: 0.8rem !important;
  }

  .content p {
    font-size: 0.8rem;
  }

  p.post{
    font-size: 0.8rem !important;
    margin-bottom: 1rem; /* å¯æ ¹æ®éœ€è¦è°ƒæ•´ä¸ºæ›´å¤§çš„å€¼ï¼Œå¦‚1.5remã€2remç­‰ */
  }

  .content ul {
    font-size: 0.8rem;
  }

  figure img {
    width: 100% !important;
  }

  figcaption {
    font-size: 0.5rem !important;
    text-align: center;
  }
}


</style>

<script>
  window.onload = function() {
    history.replaceState("", document.title, window.location.pathname + window.location.search);
  };
</script>

  <script>
    // åˆå§‹åŒ– Bulma çš„ dropdown
    document.addEventListener('DOMContentLoaded', () => {
      const dropdowns = document.querySelectorAll('.dropdown');
      dropdowns.forEach(($dropdown) => {
        $dropdown.addEventListener('click', () => {
          const $menu = $dropdown.querySelector('.dropdown-menu');
          $menu.classList.toggle('is-active');
        });
      });
    });
  </script>
</body>
</html>
